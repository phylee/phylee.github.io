---
title: 我的涂鸦三年
date: 2022-05-03 16:40:14
tags:
- Work
---

时间过的很快，我在涂鸦已经工作三年了。三年不算长，但也是我大学毕业后工作经历中很重要的三年，也是我成长最快的三年，所以也该写一个总结。回首过往，总结经验，是为了更好的面对未来挑战。下面的回顾文字，可能会有马后炮的嫌疑（当然任何回顾总结都有这种嫌疑），只作为个人工作的一小段总结，不作其他的引申。

## 2019年：打扫干净屋子

第一年刚入职不久，公司老员工相继离职，自己也不是很熟悉现有平台的开发语言，原来也没怎么写过前端（我原来写Python，现有平台后端是Java，前端是Vue.js）。平台功能大而全所以也很复杂，同时也有些稳定性的问题，挑战对我来说是前所未有的，所以头一年基本上也没有休息好一个完整的周末或者假期。

首先就是要保证平台的稳定使用。要保证稳定首先就需要化繁为简，复杂性是软件工程上的万恶之源，因为人天生就不愿意处理很复杂的东西，更别说还需要长时间的维护；其次要聚焦平台的主航道，人的精力有限无法面面具到的情况下，要优先保证平台的核心功能稳定可靠，其他次要功能能砍则砍，不能砍的也不投入过多时间，逐步下掉。

这一年主要做的工作：

> 1. 推：优先级较低的新功能需求推掉或延期支持，先保证发布核心功能的稳定。
> 2. 砍：不重要的或者不需要的功能先砍掉。
>   例如：下线工单相关、vpn权限管理、机器权限管理、需求管理等等，同时清理删除大量毁弃的代码。新的运维平台支持工单功能，就将现有的工单下掉了。
> 需求管理这块本来是需要的也是重要的，对发布平台来说，从需求管理到上线是个完整的生命周期，但是人力有限，也忍痛砍掉了（后面公司成立单独的效能团队，做了一个新的项目中心平台，当然这是后话）。
> 3. 迁：和发布平台核心不相关的功能迁移，专注自身的平台定位。
>  例如：日志报警，健康检查报警等迁移到监控平台，机器管理等相关迁移新的运维平台。
> 4. 优：故障频发的接口重点优化。使用频繁和问题多的接口能重构的重构，能优化的优化，维护成本高的难以优化的就弃用。
>  集中一段时间修复bug，当然有些也不能算bug，只是接口校验写的不够严谨，会导致大量的答疑的工作。大量bug，会导致大量时间浪费在定位以及处理数据不一致的问题，无法开展新的功能特性开发。同时接口中增加一些防御性检查，避免误操作。前端输入增加长度限制，避免超过数据库字段限制。增加重试，减少网络问题影响。在和其他平台对接时，要避免其他平台异常导致自身平台无法使用的情况，可降级，避免强依赖（当然有些强依赖是无法完全解耦的）。
> 关于bug，很多人觉得平台要做到零bug，发现bug就要立即修复甚至当天修复。我的看法是bug永远都修复不完的，也不可能投入所有精力去修复全部bug。只要开发新的功能特性就会有新的bug，我们只要保证bug降低一定范围以下同时优先级足够低即可。要重视bug但是不能被bug绊住平台演进的脚步。
> 5. 改：我们同时进行了一个大的改造，proxy重写为gateway。
>  这次大重写一方面是为了稳定性，另一方面也是为了减少我们额外支撑时间。原有的发布过程中的日志显示的很不友好，这样开发人员很多时候就不能自助定位失败问题，就会频繁找我们，浪费我们大量的支撑时间，当然也会浪费开发人员大量的找人时间。同时此次重写将部署的脚本也统一收到平台管理，在部署时自动下发。极大地降低脚本的不一致性问题和升级成本，同时让我们也能灰度发布更新这些脚本。
> 此次重写也让我们发生了一个导致业务的线上故障。当然这不能挡住我们重构的步伐，我的观点就是任何重构都有很大风险导致故障，只要重构收益大，我们就不能束手束脚。我的处理原则是：事前充分准备尽量避免，事中要尽量可灰度升级，事后要能做到快速回滚。
> 6. 减：减少处理“杂事”的时间。
>  一开始平台上有大量的事情，需要平台管理员处理，这会占用我们不少的时间，当然这也不符合我的理念，我们做的是平台，平台当然要像ATM机器一样能自助，一个开发团队可以在平台上做任何他们需要做的事（当然不是每一个开发人员都有所有权限，但是团队负责人或者应用负责人是可以有的），除非出了故障才需要找我们处理。于是我们花费了一些精力将平台管理员的权限能转移给主管的转给主管，能转移给应用负责人的就转移给应用负责人。减少平台管理员花费大量时间在平台用户权限不够的问题上。
> 理想情况下，平台的用户不需要找管理员要任何权限，因为我们做的平台应该是自助的，当然自助就有可能发生一些非主观的问题甚至故障，所以我们要做好平台用户的使用培训，对一些危险操作要二次确认，多次校验，事后要有操作日志可回溯。当然不能害怕用户犯错，就不放权，这些操作错误可以让我们不断优化平台的使用体验，减少类似错误。
> 7. 易：让平台自身做到更容易的发布，减少部署时间花费。
>  我们平台发布的应用都是使用docker镜像部署，但是发布平台自身却不是，这个是不合适的，做平台首先要eat our own dog food。我们花了一点时间，各个应用都迁移使用docker镜像部署，同时使用gitlab的CI自动构建镜像，尽量减少手动操作。当然最好是平台自己能发布自己，要像某些编程语言那样具有自举的能力（因为这个平台自身的一些设计问题，我们当时没能做到自己发布自己，后面做新平台时我们做到了，当然这是后话）。

这一年我们更多的是修修补补，我们也犯了一些错误甚至一些故障，但是最重要的是让平台自身更加完善和稳定了，做到这些是不容易的，当然这些都离不开所有同事的协作。要做好一件事，一个人当然是不行的，更需要有一个优秀的团队之间的配合。所以有些人在一个公司做的很好，换一个公司好像就没法做的像原来一样，大概也有这个原因吧。

## 2020年：再请客

经过上一年的不断完善，平台基本稳定了，同时平台的代码我们也熟悉了，新的一年我们要再出发。

这一年我们做了很多新的功能特性，增强并扩展了平台的持续交付的能力。

> 1. 拥抱云原生, 改造发布平台同时支持虚拟机部署和k8s部署
>  从19年底我们就开始初步试点k8s部署，试点没大问题后，在2020年我们开始了大规模的迁移。
> 因为原来虚拟机部署也是用的docker镜像作为制品进行发布的，所以这也让我们迁移k8s更容易，改造成本更低。最大的难度可能是分批部署，因为我们主要是云端的应用发布，能分批，小规模灰度很重要，但是k8s的原生工作负载Deployment不支持分批暂停，所以我们k8s团队基于Deployment自研了一个CRD。
> 发布平台方面在设计的时候我们要考虑到迁移后如果有问题，如何能快速迁移回去？是按照一个应用整体迁移，还是按照环境进行迁移？当然我们公司在全球有多个数据中心，多个公有云厂商，不同云厂商的k8s支持程度不一样，还是按照区域去迁移？这些都是我们要考虑的细节。
> 2. 新增按项目维度的隔离测试环境，增强测试环境的稳定性和灵活性。
>  微服务越来越多，开发人员也越来越多，测试环境的稳定性就会遇到很大的挑战。需求越来越多，大家都要测试，但是测试环境就几个，大家都在里面部署，一个服务部署有问题，就可能导致很多依赖服务测试不了。于是今年我们对日常环境做了一些改造，让原来的日常环境只部署线上最新代码并且可以线上发布完自动部署，同时虚拟出一个测试的隔离环境，一个需求的相关应用部署在一个隔离环境，打上同一个标签，其实有点写时复制的思想，当你交付的一个需求要修改的那几个应用，就新建一个项目将相关应用关联起来，打上标签进行部署，不需要修改代码的但是测试需要依赖的应用就使用日常部署了master代码的主干环境。这样可以用最少的机器同时可以虚拟出无数个测试的隔离环境（因为都打上了标签，每个标签之间不会调用，看起来是隔离的）。当然这是需要中间件，前端，客户端，云端等多部门协作和支持这个标签，不单单靠一个发布平台就能搞定的。
> 3. 持续集成的相关资源改造：由单机走向集群。
>   随着应用和开发人员的增多，任务类型也由原来的只有编译打包扩展到单元测试，代码扫描等多种类型任务，原来只有一台构建机器，已经无法满足需求，所以我们需要进行改造。但是缺少个任务调度和资源管理的平台，人力有限不可能去开发一个，正好我们在迁移k8s, 所以利用k8s作为资源池是最好的方式，同时我们引入开源的Tekon作为CI引擎。顺利的从单机迁移到k8s资源池。
> 其实这也是我一直以来想做的，就是从下载代码，编译打包，单元测试，构建镜像，部署等完整流程，都可以在一个k8s集群完成，这样我们可以充分利用k8s的能力，减少重复造轮子，而且也不会比k8s做的好。在巨人的肩膀上才能走的更远吧。
>
> 4. 多架构镜像部署：降低机器成本。
>   ARM机型的价格相对便宜很多，但是我们是多云的，有些云厂商的ARM机器支持还不是很好，所以我们要同时支持ARM64和x86-64两种架构的编译和镜像构建。主要利用docker mainfest和buildx两种方式。本来计划大规模使用buildx的，但是这个工具稳定性还不是太好，社区还在完善迭代，所以只有小部分使用。主要还是用原生的docker manifest。
> 5. 研发质量提升
>  我们支持了单元测试，代码扫描，对接研测平台，对依赖包进行检测等等，平台虽然提供了基本的能力，但是使用的还不太理想，一方面是这需要开发人员有意愿提升代码质量我们不能强制，另一方面我们时间精力有限，所以这方面投入也比较少，没有持续优化。

## 2021年：另起炉灶

这一年因为组织架构调整，团队成员也增加了不少，希望整合原有的发布平台和运维平台，做一个新研发平台。减少开发人员的使用成本。

新平台做的很不容易，中间经历多次组织架构调整，项目差点死掉，后又经历人员的拆分和减少，各种软甜苦辣吧，花了近一年的时间新平台才勉强覆盖老平台的所有功能并开始迁移。当然最后的结果是没有达到我的预期，但是中间没有死掉，还上线了，也是很不容易了，最重要的是学到了很多经验教训。

> 1. 重新梳理的已有的所有功能，加深理解，重新优化。
>  原来的平台功能很多，但是都没有整理过，这次进行了梳理，对发布平台的功能有更深的理解，例如应用，项目，编译构建，部署，流水线等等。
> 2. 如何从零开始做一个项目？
> 设计文档，我们要做哪些功能，提供哪些能力？
> 需求整理，我们如何去迭代，先做哪些，后做哪些？
> 服务划分，我们要分几个应用，功能如何划分？
> 原型设计，前端如何展示和组合？
> 迭代开发，如何分解任务、评估开发时间和人员分工?
> 开发完成，如何测试，如何上线，如何推广，如何迁移？
> 3. 对当前平台架构的新思考：当前发布平台和运维平台职责不清，如何进行整合和并调整定位？
> 当然这个不是当前的平台架构，只是我在做的过程的一些新思考，只是一个新设想。
> 以发布平台为基础，整合扩展为新的研发平台，面向开发人员的一站式平台。也就是只要是开发人员需要的功能只在这一个平台里操作就行，从需求，开发，部署，上线，日志，监控数据反馈一体化。后端数据可以分开多个服务，前端要整合一个页面。
> 以运维平台为基础，整合扩展为多云的管理平台和公司基础运维数据存储，面向运维人员的一站式平台。首先将开发人员需要使用的功能迁移研发平台，避免开发人员多个平台跳转，也就是说这个平台不再对开发人员开放，只面向运维人员，这里的运维是广义的，包括业务运维，系统运维，DBA，k8s集群管理员等等。专注于封装各公有云，私有云的操作，尽量减少公司内运维人员到各云厂商控制台上的操作，只要在该平台上就可以操作所有云。后期这个平台可以独立部署私有云售卖或者开源。
> 4. 对重构平台的思考
> 尽量减少新平台从内部开发到对外使用的时间。长时间不对外使用，不可预知的风险（包括技术的和非技术的）就会很高。
> 可以分模块重构，尽量避免从零开始完全重做，因为这样会导致时间周期很长。
> 数据库除如果要独立使用，不和老平台复用，要多考虑中间过程数据一致性和迁移的成本。
> 尽量减少重构对平台用户和其他第三方平台的影响。
> 做好一个平台，技术很重要，但光关注技术不行，非技术原因如果处理不好，也很容易让一个平台烂尾掉。

## 反思

这几年我也做了很多在今天看来不是很好的决定，有时我想如果重新做一次决定，会不会更好？我想是不会的，有些是当时的个人能力和当时的外在条件限制决定的，不能马后炮，也不要用上帝视角，但可以反思一下，让以后做的更好一点。
